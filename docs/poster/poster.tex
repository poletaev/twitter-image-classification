 \documentclass[a0paper,
   portrait,
   innermargin=25mm,
   blockverticalspace=25mm,
   colspace=25mm,
   subcolspace=40mm
]{tikzposter}
\title{Classification and mapping Twitter images}
\author{Andrey~Poletaev^1, Nikita~Debelov^2, Maxim~Ryabinskiy^3}
\institute % (optional, but mostly needed)
{
  ^1Crystallnix, LLC, Omsk,\\
  ^2Northern (Arctic) Federal University, Arkhangelsk,\\
  ^3Seismotech, LLC, Moscow
}

\usetheme{Simple}
\usecolorstyle{Russia}
\colorlet{blocktitlebgcolor}{rgb:red,1;green,2;blue,3}
\colorlet{blocktitlefgcolor}{rgb:red,1;green,2;blue,3}

 \begin{document}
     \maketitle
     \begin{columns}
       \column{0.5}{
       \block{Overview}{
         Originally this project was built in a quite short period of time during Microsoft Research Russia Summer School ``Doing Research in the Cloud''~\cite{microsoft_cloud2014}. The main idea of this project is to collect, analyze and visualize data from social network Twitter.
         The first version was build on Microsoft Azure platform and heavily utilises it's tools such as Queue Service, Blob storage service, Table service, SQL Azure Database, Bing Maps API. The system was launched on three trial accounts provided by Microsoft for school participants.
         The second version was build with using Celery~\cite{celery}, a distributed task queue -- system to process messages while providing operations with the tools required to maintain such a system.
         In both cases to use Twitter API -- subscribe and receive tweets with both image and geotag, a Python library Tweepy~\cite{tweepy} was used.
       }

       \block{Architecture of first version}{
         \begin{tikzfigure}[]
           \includegraphics[width=35cm]
                           {../images/v1}
         \end{tikzfigure}
       }
       \block{Web interface (first version)}{
         \begin{tikzfigure}[]
           \includegraphics[height=13cm]
                           {../images/airplane}
           \includegraphics[height=13cm]
                           {../images/v1_promontory}
         \end{tikzfigure}
       }
      \block{Web interface (second version)}{
         \begin{tikzfigure}[]
           \includegraphics[height=13cm]
                           {../images/v2_food}
           \includegraphics[height=13cm]
                           {../images/v2_castle}
           \includegraphics[height=13cm]
                           {../images/v2_trifle}
         \end{tikzfigure}
       }
       }

       \column{0.5}{
       \block{Architecture of second version}{
         \begin{tikzfigure}[]
           \includegraphics[width=35cm]
                           {../images/v2}
         \end{tikzfigure}
       }
       \block{Image classification}{
         A deep convolutional neural network was used as the classifier for images obtained from Twitter. Python library Caffe~\cite{caffe} with prebuilt Berkeley Vision and Learning Center (BVLC) CaffeNet Model were utilized. This model is a replication of an ImageNet model~\cite{nips2012} trained on the ILSVRC-2012 data set. It was released by BVLC for unrestricted use.

         Here is the short overview of the model: the best validation performance during training was on iteration 313,000 with validation accuracy 57.412\% and loss 1.82328.
This model obtains a top-1 accuracy 57.4\% and a top-5 accuracy 80.4\% on the validation set.
         Max-pooling layers follow first, second, and fifth convolutional layers.
         The number of neurons in each layer is given by 253440, 186624, 64896, 64896, 43264, 4096, 4096, 1000.~\cite{nips2012}

         \begin{tikzfigure}[]
           \includegraphics[width=35cm]
                           {../images/nips2012}
         \end{tikzfigure}
       }
       \block{References}{
         \renewcommand{\section}[2]{}%
         \bibliography{poster}
       }
     }
     \end{columns}

 \end{document}
